TF-hub

1. 모델 설명
Tensorflow Hub와 Keras를 사용한 기초적인 전이 학습 어플리케이션으로 
pre-trained 된 텍스트 임베딩 모델을 Tensorflow Hub에 있는 사전 훈련된 텍스트 임베딩 모델로 사용했다. 
차원의 크기 20 ~ 128 vocab 크기 1백만 개 이하를 사용한 모델들을 사용할 수 있다.

2. 사용한 데이터
IMDB

3. 참고한 github 사이트 및 논문
https://github.com/tensorflow/docs-l10n

4. 실행 과정
해당 코드를 colab과 연동해서 gpu 가속기를 통해 실행 했다.
기존 코드 그대로 실행 시 표기된 성능보다 2% 낮아서 batch size나 epoch조절을 해도 더 올라가지 않아서 
차원의 크기가 더 큰 다른 모델들을 넣어서 돌려보았는데 오히려 성능이 떨어져서 
layer를 추가해보고 optimizer 함수를 바꿔봐도 기존 85% 성능을 넘지 못하였다.

5. 실행 결과

표기된 성능인 87%에 비해 85%의 성능밖에 보이지 못했다.
